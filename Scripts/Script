#####Problem Set 2 - Group 6#####


#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%    Data Cleaning    		          %
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
##Paquetes 
rm(list = ls())
install.packages("devtools")
require("pacman")
install.packages("ggpubr")
library(faraway)
library(tidyverse)
library(skimr)
#devtools::install_github("boxuancui/DataExplorer")
library(DataExplorer)
library(scales)
library(corrr)
library("MASS")
library("class")
library("dplyr") #for data wrangling
library("gamlr")
library("ROCR") #Roc
library(dplyr)
library(glmnet)
library(pls)
devtools::install_github("thomasp85/patchwork")
p_load(rvest)
p_load(rio) 
p_load(tidyverse)
p_load(e1071) 
p_load(EnvStats) 
p_load(tidymodels) 
p_load(ggplot2) 
p_load(scales) 
p_load(ggpubr) 
p_load(knitr) 
p_load(kableExtra)
p_load(broom)
p_load(caret)
library(patchwork)

##Se leen y almacenan las bases de datos
train_individual <- readRDS("data 2/train_personas.Rds")

dim(train_individual)
str(train_individual)

##La base de entrenamiento de personas cuenta con 135 variables y 543584 observaciones

train_hogares <- readRDS("data 2/train_hogares.Rds")
head(train_hogares[c("Pobre")])

dim(train_hogares)
str(train_hogares)

##La base de entrenamiento de hogares cuenta con 23 variables y 164960 observaciones

test_individual <- readRDS("data 2/test_personas.Rds")
dim(test_individual)
str(test_individual)

##La base de testeo de personas cuenta con 63variables y 219169 observaciones


test_hogares <- readRDS("data 2/test_hogares.Rds")
dim(test_hogares)
str(test_hogares)
##La base de testeo de hogares cuenta con 16 variables y 66168 observaciones

##Teniendo en cuenta que en la base de testeo solo hay 16 variables, en los modelos a
##plantear con la base de entrenamiento únicamente se tendran en cuenta estas variables
#Se verifica entonces cuáles variables tienen en común

vth <- ls(train_hogares)
vtsh <- ls(test_hogares)
Coincidencias <- list()

for(i in 1:length(vtsh)){
  for(j in 1:length(vth)){
    if (vtsh[i]==vth[j]){
      Coincidencias <- append(Coincidencias, vtsh[i])
    }
  }
}
Coincidencias

##Se observa que la base de test no tiene construida la variable dicótoma de "Pobre"
#La línea de pobreza monetaria per cápita nacional en  2018 fue $257.433, en el caso de un hogar de 4 personas fue $1.029.732


#---------Limpieza de los datos-------------------------------------------

#Se puede observar que las bases no tienen el mismo número de variables
#Primero vamos a dejar las variables que están en las dos bases train y test incluyendo las de pobres, e ingresos totales
train_individual <- train_individual %>% dplyr::select(colnames(test_individual), Ingtot)
train_hogares <- train_hogares %>% dplyr::select(colnames(test_hogares), Ingtotug, Ingpcug, Pobre)


#Ahora se convertiran en factores las que son necesarias
train_individual <- train_individual %>%
  mutate_at(.vars = c(
    "P6050", "P6090", "P6210", "P6240", "Oficio", "P6430", "P6510", "P6545",
    "P6580", "P6585s1", "P6585s2", "P6585s3", "P6585s4", "P6590", "P6600", 
    "P6610", "P6620", "P6630s1", "P6630s2", "P6630s3", "P6630s4", "P6630s6",
    "P6800", "P6920", "P7040", "P7045", "P7090", "P7495", "Pet", "Oc", "Des", "Ina"),
    .funs = factor)

test_individual <- test_individual %>%
  mutate_at(.vars = c(
    "P6050", "P6090", "P6210", "P6240", "Oficio", "P6430", "P6510", "P6545",
    "P6580", "P6585s1", "P6585s2", "P6585s3", "P6585s4", "P6590", "P6600", 
    "P6610", "P6620", "P6630s1", "P6630s2", "P6630s3", "P6630s4", "P6630s6",
    "P6800", "P6920", "P7040", "P7045", "P7090", "P7495", "Pet", "Oc", "Des", "Ina"),
    .funs = factor)

#Volvemos P6020 Dummie para Mujer
train_individual <- train_individual %>% dplyr::rename(Mujer = P6020)
train_individual <- train_individual %>% mutate(Mujer = ifelse(Mujer == 2, 1, 0))

test_individual <- test_individual %>% dplyr::rename(Mujer = P6020)
test_individual <- test_individual %>% mutate(Mujer = ifelse(Mujer == 2, 1, 0))


#Cambiamos el nombre de P6040 por Edad
train_individual <- train_individual %>% dplyr::rename(Edad = P6040)
test_individual <- test_individual %>% dplyr::rename(Edad = P6040)

#Ahora se comprueba si la suma de los ingresos totales de los individuos del hogar es igual al del hogar como tal
prueba <- train_individual %>%
          group_by(id) %>%
          summarise(ingresostothogar = sum(Ingtot, na.rm = T))
                    
prueba2 <- left_join(prueba, train_hogares , by = "id") 
prueba2 <- prueba2 %>% dplyr::select(id, Ingtotug, ingresostothogar)
prueba2 <- prueba2 %>% mutate(Igual = Ingtotug == ingresostothogar)
table(prueba2$Igual)
prop.table(table(prueba2$Igual))

#Solamente el dos porciento de los hogares tiene ingresos diferentes y es por poco. Por lo que se puede asumir que la suma de los ingresos es correcta

#Ahora se verificará si los ingresos del jefe del hogar son la mayor proporción de los ingresos del hogar para verificar si es necesario introducir más variables
#De los demás miembros del hogar
IngresosJefeHogar <- train_individual %>% dplyr::select(id, Orden, P6050, Ingtot) %>%
                    filter(P6050 == 1)
prueba2 <- left_join(prueba2, IngresosJefeHogar , by = "id")
prueba2$ProporcionIngresosJefe <- prueba2$Ingtot/prueba2$Ingtotug
mean(prueba2$ProporcionIngresosJefe, na.rm = T)

#Los ingresos del jefe de hogar en promedio son del 65% de los ingresos totales
#Esto muestra que se puede incluir solo la información de la cabeza del hogar para determinar si el hogar es pobre o no
#En el modelo
#Del jefe del hogar se incluirán todas las variables, de la segunda persona el sexo, la edad, la educación, p6240, ocu, des, ina, P6920
TrainJefeHogar <- train_individual %>% filter(Orden == 1)

#Solo estas variables
TrainJefeHogar <- TrainJefeHogar %>% dplyr::select(id, Mujer, Edad, P6090, P6210, P6240, Oficio, P6426, P6430, P6510, P6545,
                                P6580, P6585s1, P6585s2, P6585s3, P6585s4, P6590, P6600,  
                                P6610, P6620, P6630s1, P6630s2, P6630s3, P6630s4, P6630s6,
                                P6800, P6920, P7040, P7045, P7090, P7495, Pet, Oc, Des, Ina)
#Cambiamos nombres
TrainJefeHogar <- TrainJefeHogar %>% dplyr::rename(JefeMujer = Mujer, EdadJefe = Edad, SSJefe = P6090, EducacionJefe = P6210, ActividadJefe = P6240, OfJefe = Oficio, 
                                                   TiempoEmpresaJefe = P6426, TipoTrabajoJefe = P6430,  JefeHorasExtras = P6510, JefePrimas = P6545,
                                                   BonosJefe = P6580, SubAliJefe = P6585s1, SubTranJefe = P6585s2, SubFamiliarJefe = P6585s3, SubEducativo = P6585s4, 
                                                   AlimentosJefe = P6590, ViviendaJefe = P6600, 
                                                   TransporteJefe = P6610, EspecieJefe = P6620, PrmJefe= P6630s1, NavidadJefe = P6630s2, 
                                                   VacacionesJefe = P6630s3, ViaticosJefe = P6630s4, BonosAnJefe = P6630s6,
                                                   HorasTrabJefe = P6800, PensionJefe = P6920, SegundTrabajoJefe = P7040, horassecJefe =P7045, 
                                                   QuiereMasHorasJefe = P7090, ArriendosPenJefe = P7495)

#Se une con la base de hogares
TrainDF <- left_join(train_hogares, TrainJefeHogar, by = "id")

#Hacer lo mismo para el test
testJefeHogar <- test_individual %>% filter(Orden == 1)

#Solo estas variables
testJefeHogar <- testJefeHogar %>% dplyr::select(id, Mujer, Edad, P6090, P6210, P6240, Oficio, P6426, P6430, P6510, P6545,
                                                   P6580, P6585s1, P6585s2, P6585s3, P6585s4, P6590, P6600,  
                                                   P6610, P6620, P6630s1, P6630s2, P6630s3, P6630s4, P6630s6,
                                                   P6800, P6920, P7040, P7045, P7090, P7495, Pet, Oc, Des, Ina)
#Cambiamos nombres
testJefeHogar <- testJefeHogar %>% dplyr::rename(JefeMujer = Mujer, EdadJefe = Edad, SSJefe = P6090, EducacionJefe = P6210, ActividadJefe = P6240, OfJefe = Oficio, 
                                                   TiempoEmpresaJefe = P6426, TipoTrabajoJefe = P6430,  JefeHorasExtras = P6510, JefePrimas = P6545,
                                                   BonosJefe = P6580, SubAliJefe = P6585s1, SubTranJefe = P6585s2, SubFamiliarJefe = P6585s3, SubEducativo = P6585s4, 
                                                   AlimentosJefe = P6590, ViviendaJefe = P6600, 
                                                   TransporteJefe = P6610, EspecieJefe = P6620, PrmJefe= P6630s1, NavidadJefe = P6630s2, 
                                                   VacacionesJefe = P6630s3, ViaticosJefe = P6630s4, BonosAnJefe = P6630s6,
                                                   HorasTrabJefe = P6800, PensionJefe = P6920, SegundTrabajoJefe = P7040, horassecJefe =P7045, 
                                                   QuiereMasHorasJefe = P7090, ArriendosPenJefe = P7495)

#Se une con la base de hogares
testDF <- left_join(test_hogares, testJefeHogar, by = "id")


#Borramos algunos DF para liberar espacio
remove(testJefeHogar, TrainJefeHogar, prueba, prueba2, IngresosJefeHogar)


##Estadísticas descriptivas de los datos


#Comenzamos con las variables del train de hogares que serán las que principalmente se van a utilizar
##Tratamiento de missing values

cantidad_na <- sapply(TrainDF, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(TrainDF) #Le saco el porcentaje de Missing values a cada variable

# Porcentaje de observaciones faltantes. 
porcentaje <- mean(porcentaje_na[,1]) 
print(paste0("En promedio el ", round(porcentaje*100, 2), "% de las entradas están vacías"))

##"En promedio el 11.59% de las entradas están vacías"

##Ordenamos de mayor a menor
porcentaje_na <- arrange(porcentaje_na, desc(cantidad_na))
# Convertimos el nombre de la fila en columna
porcentaje_na <- rownames_to_column(porcentaje_na, "variable")

# Quitamos las variables que no tienen NAs
filtro <- porcentaje_na$cantidad_na == 0
variables_sin_na <- porcentaje_na[filtro, "variable"]
str_count(variables_sin_na) #Hay 21 variables sin NA
variables_sin_na <- paste(variables_sin_na, collapse = ", ")
print(paste("Las variables sin NAs son:", variables_sin_na))

##Las variables sin NAs son 18
porcentaje_na <- porcentaje_na[!filtro,] #Quedan solo 46 variables con NAs

orden <- porcentaje_na$variable[length(porcentaje_na$variable):1] #Se vuelven caracteres
porcentaje_na$variable <- factor(porcentaje_na$variable,
                                 levels = orden) #Se utilizan como factores para poder graficar

str(porcentaje_na) # Se revisa el tipo de variables

# Como son tantas variables vamos a hacer una gráfica con los que tienen menos NAs
#para analizar si se pueden imputar los valores

ggplot(porcentaje_na[1:nrow(porcentaje_na),], 
       aes(y = variable, x = cantidad_na)) +
  geom_bar(stat = "identity", fill = "darkslategray3") +
  geom_text(aes(label = paste0(round(100*cantidad_na, 1), "%")),
            colour = "white", position = "dodge", hjust = 1.3,
            size = 2, fontface = "bold") +
  theme_classic() +
  labs(x = "Porcentaje de NAs", y = "Variables") +
  scale_x_continuous(labels = scales::percent, limits = c(0, 1))

##Se observa que las variables que tienen mayor cantidad de missings son aquellas en las 
#que las personas puede que no paguen arriendo o amortización. 


##Se observa que las variables que tienen mayor cantidad de missings son aquellas en las 
#que las personas puede que no paguen arriendo o amortización. 
#Se creará una variable que combine P5130 y P5140 como arriendos
TrainDF$Arriendo = ifelse(is.na(TrainDF$P5130)==F, TrainDF$P5130, TrainDF$P5140)
testDF$Arriendo = ifelse(is.na(testDF$P5130)==F, testDF$P5130, testDF$P5140)

#Tambien se actualizaran las de ocupados
TrainDF$OcupadoJefe = ifelse(is.na(TrainDF$Oc)==F, 1, 0)
testDF$OcupadoJefe = ifelse(is.na(testDF$Oc)==F, 1, 0)

#Asimismo la variable de experiencia tiene un gran porcentaje de missing values por lo que se eliminará
filtro2 <- porcentaje_na$cantidad_na > 0.30
variables_eliminadas <- porcentaje_na$variable[filtro2]
TrainDF_clean <- TrainDF %>%
  dplyr::select(-variables_eliminadas) 
k0 <- ncol(TrainDF)
k1 <- ncol(TrainDF_clean)
print(paste("Se eliminaron", k0-k1, "variables. Ahora la base tiene", k1, "columnas."))

#EliminarUnasVariables que no se usarán
TrainDF_clean <- TrainDF_clean %>% dplyr::select(-Fex_c, -Fex_dpto, -Li, -Pet, -Oc)

#Se imputaran las variables de NA
tibble(TrainDF_clean)
summary(TrainDF_clean)
str(TrainDF_clean)
#Se revisa que si las personas no están ocupadas hay un número significativo de NAs. Entonces, cuando este
#sea el caso los valores de las variables relacionadas con eso se volveran el menor factor, es decir, 0.
table(TrainDF_clean$OfJefe)

cantidad_na <- sapply(TrainDF_clean, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(TrainDF_clean) #Le saco el porcentaje de Missing values a cada variable

#Factor 0 para los no ocupados en Oficio
view(filter(TrainDF_clean, OcupadoJefe==0)) #Todos son NAs

TrainDF_clean$OfJefe<- as.numeric(TrainDF_clean$OfJefe)
TrainDF_clean$OfJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, 0, TrainDF_clean$OfJefe)
TrainDF_clean$OfJefe<- as.factor(TrainDF_clean$OfJefe)

TrainDF_clean$TiempoEmpresaJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, 0, TrainDF_clean$TiempoEmpresaJefe)
TrainDF_clean$TipoTrabajoJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, "0", TrainDF_clean$TipoTrabajoJefe)
TrainDF_clean$HorasTrabJefe <- as.numeric(TrainDF_clean$HorasTrabJefe)
TrainDF_clean$HorasTrabJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, 0, TrainDF_clean$HorasTrabJefe)
TrainDF_clean$PensionJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, "2", TrainDF_clean$PensionJefe)
TrainDF_clean$SegundTrabajoJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, "2", TrainDF_clean$SegundTrabajoJefe)
TrainDF_clean$QuiereMasHorasJefe <- ifelse(TrainDF_clean$OcupadoJefe == 0, "2", TrainDF_clean$QuiereMasHorasJefe)

cantidad_na <- sapply(TrainDF_clean, function(x) sum(is.na(x))) #Una función que me suma el número de NAs por variable
cantidad_na <- data.frame(cantidad_na) #Lo convierto en Data Frame
porcentaje_na <- cantidad_na/nrow(TrainDF_clean) #Le saco el porcentaje de Missing values a cada variable
view(filter(TrainDF_clean, is.na(PensionJefe)==T))

#Cambiar las NAs faltantes según su análisis
TrainDF_clean <- mutate(TrainDF_clean, PensionJefe = ifelse(is.na(PensionJefe)==T, "2", PensionJefe))
TrainDF_clean <- mutate(TrainDF_clean, SSJefe = ifelse(is.na(SSJefe)==T, "2", SSJefe))
TrainDF_clean <- mutate(TrainDF_clean, ActividadJefe = ifelse(is.na(ActividadJefe)==T, "6", ActividadJefe))
TrainDF_clean <- mutate(TrainDF_clean, ArriendosPenJefe = ifelse(is.na(ArriendosPenJefe)==T, "2", ArriendosPenJefe))

#La Base ya está limpia
variables_clean <- colnames(TrainDF_clean)
variables_clean <- variables_clean[-11]
variables_clean <- variables_clean[-11]
variables_clean <- variables_clean[-11]

testDF <- dplyr::select(testDF, variables_clean)


testDF$OfJefe<- as.numeric(testDF$OfJefe)
testDF$OfJefe <- ifelse(testDF$OcupadoJefe == 0, 0, testDF$OfJefe)
testDF$OfJefe<- as.factor(testDF$OfJefe)

testDF$TiempoEmpresaJefe <- ifelse(testDF$OcupadoJefe == 0, 0, testDF$TiempoEmpresaJefe)
testDF$TipoTrabajoJefe <- ifelse(testDF$OcupadoJefe == 0, "0", testDF$TipoTrabajoJefe)
testDF$HorasTrabJefe <- as.numeric(testDF$HorasTrabJefe)
testDF$HorasTrabJefe <- ifelse(testDF$OcupadoJefe == 0, 0, testDF$HorasTrabJefe)
testDF$PensionJefe <- ifelse(testDF$OcupadoJefe == 0, "2", testDF$PensionJefe)
testDF$SegundTrabajoJefe <- ifelse(testDF$OcupadoJefe == 0, "2", testDF$SegundTrabajoJefe)
testDF$QuiereMasHorasJefe <- ifelse(testDF$OcupadoJefe == 0, "2", testDF$QuiereMasHorasJefe)


##En búsqueda de valores atípicos se realizan gráficos de cajas y análisis de correlaciones

##Distribución número de cuartos
d1 <- ggplot(TrainDF_clean, aes(y = P5000)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Número de cuartos") +
  scale_x_discrete( ) 

##Distribución ingresos totales
d2 <- ggplot(TrainDF_clean, aes(y = Ingtotugarr)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Ingresos totales") +
  scale_y_continuous(labels = scales::dollar) +
  scale_x_discrete( ) 

##Distribución ingresos totales per cápita
d3 <- ggplot(TrainDF_clean, aes(y = Ingpcug)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Ingresos totales per cápita") +
  scale_y_continuous(labels = scales::dollar) +
  scale_x_discrete( ) 

##Distribución Número de personas en el hogar
d4 <- ggplot(TrainDF_clean, aes(y = Nper)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Número de personas") +
  scale_y_continuous(labels = scales::dollar) +
  scale_x_discrete( ) 

ggarrange(d1, d2, d3, d4, d5, nrow = 3, ncol = 2)
(d1 | d2) /
  (d3 | d4)

#Pobre
ggplot(TrainDF_clean, aes(Pobre)) + geom_bar()
prop.table(table(TrainDF_clean$Pobre))


##Distribución educación
d5 <- ggplot(TrainDF_clean, aes(as.factor(P6210c.mean), Ingtotugarr)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Ingresos totales") +
  scale_y_continuous() +
  scale_x_discrete( ) 
d5
##Distribución por ingreso y pobreza
d6 <- ggplot(TrainDF_clean, aes(as.factor(Pobre), Ingtotugarr)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Ingreso total") +
  scale_y_continuous() +
  scale_x_discrete( ) 

d7 <- ggplot(TrainDF_clean, aes(as.factor(Clase), Ingtotugarr)) +
  geom_boxplot(fill = "darkslategray3", alpha = 0.5) +
  theme_classic() +
  labs(y = "Ingreso total") +
  scale_y_continuous() +
  scale_x_discrete( ) 

(d7 | d6) /
  (d5)

by1 <- ggplot(data=TrainDF_clean) +
  geom_histogram(mapping=aes(x=Ingtotugarr , group= as.factor(Pobre), fill=as.factor(Pobre))) + 
  theme_classic()
by1 + scale_fill_manual(values =c("0"="darkslategray3", "1"="blue"), label=c("0"="No Pobre", "1"="Pobre"), name="Sexo")

by2 <- ggplot(data=TrainDF_clean) +
  geom_histogram(mapping=aes(x=Ingtotugarr , group= as.factor(P6210c.mean), fill=as.factor(P6210c.mean))) + 
  theme_classic()
by2 + scale_fill_manual(values =c("1"="darkslategray3", "2"="blue", "3"="aquamarine4", "4"="azure3", "5"="chartreuse4", "6"="chocolate3", "9"="coral2"), 
                        label=c("1"="Ninguno", "2"="Preescolar", "3"="Básica Primaria", "4"="Básica Secundaria", "5"="Media", "6"="Superior o universitaria", "9"="No sabe"), name="Nivel Educativo")


#Tablas

vartable <- st(TrainDF_clean, vars = c('Ingtotugarr','Ingpcug', 'P5000', 'Nper'), labels = c("Ingresos Totales", "Ingresos Totales per cápita", "Cuartos", "Personas del Hogar"))


##Correlaciones
# Primero seleccionamos las columnas numéricas
#Se obtienen las correlaciones
correla <- TrainDF_clean[c('Ingtotugarr','Ingpcug', 'P5000', 'Nper')]
mcor <- round(cor(correla[, unlist(lapply(correla, is.numeric))]),2)
#Se mantiene toda la tabla
upper<-mcor
upper[upper.tri(mcor)]<-""
upper<-as.data.frame(upper)

corrplot(cor(correla[, unlist(lapply(correla, is.numeric))]))
write_xlsx(upper,"Correla.xlsx")


#Pobre
ggplot(TrainDF_clean, aes(Pobre)) + geom_bar()
prop.table(table(TrainDF_clean$Pobre))

#La base está desbalanceada. Es necesario hacer un balanceo de muestra cuando se corran los modelos
glimpse(TrainDF_clean)

TrainDF_clean <- TrainDF_clean %>%
  mutate_at(.vars = c(
    "TipoTrabajoJefe", "PensionJefe", "SegundTrabajoJefe", "QuiereMasHorasJefe"),
    .funs = factor)

testDF <- testDF %>%
  mutate_at(.vars = c(
    "TipoTrabajoJefe", "PensionJefe", "SegundTrabajoJefe", "QuiereMasHorasJefe"),
    .funs = factor)


TablaEstadiscticas <- TrainDF_clean %>%
  skim()


#Vamos a volver Dummies las variables categoricas
p_load(fastDummies)

filtro <- !sapply(TrainDF_clean, is.numeric)
categoricas <- names(TrainDF_clean)[filtro]
categoricas <- categoricas[c(2, 5, 6, 7, 9, 10, 11, 12, 13)]


for (var in categoricas) {
  frecuencia <- prop.table(table(TrainDF[, var]))
  len <- nrow(frecuencia)
  print(paste("Cantidad de valores únicos para la variable", var, "son:", len))
  frecuencia <- round(100*frecuencia, 1)
  print(frecuencia)
}

TrainDF_clean <- dummy_cols(TrainDF_clean, select_columns = categoricas,
                remove_first_dummy = T,
                remove_selected_columns = T)


#Ahora en el set de Test
filtro <- !sapply(testDF, is.numeric)
categoricas <- names(testDF)[filtro]
categoricas <- categoricas[c(2, 5, 6, 7, 9, 10, 11, 12, 13)]

for (var in categoricas) {
  frecuencia <- prop.table(table(testDF[, var]))
  len <- nrow(frecuencia)
  print(paste("Cantidad de valores únicos para la variable", var, "son:", len))
  frecuencia <- round(100*frecuencia, 1)
  print(frecuencia)
}

testDF <- dummy_cols(testDF, select_columns = categoricas,
                            remove_first_dummy = T,
                            remove_selected_columns = T)


#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%    Classification Models   		          %
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#-------------1 Modelo Random Forest

set.seed(1948)
index <-  round(nrow(TrainDF_clean)*0.3,digits=0)
#Muestra aleatorizada del  dataset y mantener el número de observaciones del indice
test.indices <- sample(1:nrow(TrainDF_clean), index)
# set de entrenamiento
hogares_train<-TrainDF_clean[-test.indices,] 
#30% set de testeo
hogares_test<-TrainDF_clean[test.indices,] 
#Seleccionar el set de entrenamiento en variables independientes y dependientes
YTrain <- hogares_train$Pobre
XTrain <- hogares_train %>% dplyr::select(-Pobre)
#Seleccionar el set de testeo en variables independientes y dependientes
YTest <- hogares_test$Pobre
XTest <- hogares_test %>% dplyr::select(- Pobre)

#Balancear la muestra de pobres
#Paquete que me hace el resamsampling teniendo en cuenta la proporción 50-50
p_load(ROSE)
hogares_train <- dplyr::select(hogares_train, -id, -Dominio, -Depto, -OfJefe)
hogares_train$Pobre <- as.numeric(hogares_train$Pobre)
hogares_train_bal <- ovun.sample(Pobre ~ ., data = hogares_train, method="both", p=0.5, seed = 1948)
hogares_train_bal <- hogares_train_bal$data
table(hogares_train_bal$Pobre)
hogares_train_bal <- dplyr::select(hogares_train_bal, -Ingtotug, -Ingpcug)
YTrain_bal <- hogares_train_bal$Pobre
XTrain_bal <- dplyr::select(hogares_train_bal, -Pobre)

XTest <- hogares_test %>% dplyr::select(-id, -Dominio, -Depto, -OfJefe, -Ingtotug, -Ingpcug, -Pobre)

#Modelo Random Forest
p_load(caret)
p_load(randomForest)


set.seed(1948)
trControl <- trainControl(method='repeatedcv', 
                          number=5, 
                          repeats=1,
                          allowParallel = TRUE,
                          summaryFunction = multiClassSummary)

ModeloForestTodo <- train(
                      as.factor(Pobre) ~ .,
                      data = hogares_train_bal,
                      method = "rf",
                      trControl = trControl,
                      maxnode = 5,
                      metric = "Sens",
                      ntree = 300)


ModeloForestTodo
plot(ModeloForestTodo)
varImp(ModeloForestTodo,scale=TRUE)

pred_RF <- predict(ModeloForestTodo, XTest)

confusionMatrix(table(YTest, pred_RF))

p_load(ROCR)

YProb_RF <- predict(ModeloForestTodo, XTest, type ="prob")
pred_RFs <- prediction(YProb_RF[,2], as.numeric(YTest))
perf_RFs <- performance(pred_RFs,"tpr","fpr")

aucRFs <- performance(pred_RFs,"auc")@y.values
aucRFs

plot(perf_RFs,colorize=TRUE)

#Se guardan los valores porque el modelo se demora 2 horas corriendo
AccuracyRF = 0.6667
AUCRF = 0.8365954
PrecisionRF = 24133/(1155+24133)
SensitivityRF = 24133/(24133+15341) 
SpecificityRF = 8859/ (8859+1155)


#---------------- Modelos con variables específicas-------------------------

require(caret)
require("gtsummary")
TrainDF_clean$Pobre <- haven::as_factor(TrainDF_clean$Pobre)
testDF$Clase_2 <- haven::as_factor(testDF$Clase_2)
TrainDF_clean$Clase_2 <- haven::as_factor(TrainDF_clean$Clase_2)
TrainDF_clean$TipoTrabajoJefe_1 <- haven::as_factor(TrainDF_clean$TipoTrabajoJefe_1)
TrainDF_clean$PensionJefe_2 <- haven::as_factor(TrainDF_clean$PensionJefe_2)
TrainDF_clean$EducacionJefe_6 <- haven::as_factor(TrainDF_clean$EducacionJefe_6)
TrainDF_clean$OcupadoJefe <- haven::as_factor(TrainDF_clean$OcupadoJefe)
TrainDF_clean$P5090 <- haven::as_factor(TrainDF_clean$P5090)




tbl_summary(TrainDF_cleanF)
tbl_summary(TrainDF_cleanF,by = Pobre, statistic = list(all_continuous() ~ "{mean} ({sd})"))

##Se crean tres bases la de testeo, evaluación y prueba
set.seed(112)
split1 <- createDataPartition(TrainDF_clean$Pobre, p = .7)[[1]]
length(split1)
##Longitud de 115.471 observaciones
levels(TrainDF_clean$Pobre) <- c("No_Pobre", "Pobre")

other <- TrainDF_clean[-split1,]
training <- TrainDF_clean[ split1,]

##La de evaluación para post-procesamiento 
set.seed(123)
split2 <- createDataPartition(other$Pobre, p = 1/3)[[1]]
evaluation <- other[ split2,]
testing <- other[-split2,]

dim(training) ##115471 observaciones
dim(testing) ##32990 observaciones
dim(evaluation) ##16496 observaciones

##Se prueban diferentes modelos para encontrar el más pertinente 

#Método de validación cruzada con cinco folds- se corta en cinco la base
ctrl_def <- trainControl(method = "cv",
                         number = 5,
                         summaryFunction = defaultSummary,
                         classProbs = TRUE,
                         verbose=FALSE,
                         savePredictions = T)

#Logit- fijo la semilla y aplico un logit con función binomial y las variables escaladas
set.seed(1234)
mylogit_caret_def <- train(
  Pobre ~ Arriendo + PensionJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl_def,
  family = "binomial",
  preProcess = c("center", "scale")
)
mylogit_caret_def
##Al correr el logit con la base de training se obtiene un accuracy de 0.80 y Kappa de 0.11. Es decir, que un 80% de las observaciones totales
##se clasificaron de manera correcta. El Kappa indica que hay poca concordancia entre los rates utilizados en el modelo. 

##Se corre lo mismo pero sacar más métricas del modelo

ctrl_two <- trainControl(method = "cv",
                         number = 5,
                         summaryFunction = twoClassSummary,
                         classProbs = TRUE,
                         verbose=FALSE,
                         savePredictions = T)

set.seed(1234)
mylogit_caret_two <- train(
  Pobre ~ Arriendo + PensionJefe_2+ TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl_two,
  family = "binomial",
  preProcess = c("center", "scale")
)

mylogit_caret_two


fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
ctrl<- trainControl(method = "cv",
                    number = 5,
                    summaryFunction = fiveStats,
                    classProbs = TRUE,
                    verbose=FALSE,
                    savePredictions = T)
#logit
set.seed(18414)
mylogit_caret <- train(
  Pobre ~ Arriendo + PensionJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl,
  family = "binomial",
  preProcess = c("center", "scale")
)

mylogit_caret

## El área bajo la curva (ROC) es del 0.76, la Sensibilidad es de un 98% es decir que se detectan correctamente el 98% de los pobres que en verdad son pobres, y la especificidad es de 0.08, es decir que un 8% de los verdaderos no pobres son clasificados como tal.
##La métrica más relevante para este caso es la de sensibilidad debido a que quiero predecir los hogares debajo de la línea de pobreza.

##Para verificar la pertinencia de incluir las variables especificadas con anterioridad en el modelo se utiliza lasso con una grilla de 200
##A partir de esto se observa las diferentes penalizaciones y escogemos el lambda que maximiza la sensibilidad del modelo. Asimismo, se prueba Ridge y elastic net para elegir cuál funciona mejor.
#Lasso
lambda_grid <- 10^seq(-4, 0.01, length = 200) #en la practica se suele usar una grilla de 200 o 300
lambda_grid

set.seed(58694)
mylogit_lasso_acc <- train(
  Pobre ~ Arriendo + PensionJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_acc
##Con un alpha de cero (lasso) el lambda óptimo es de 1.023293



set.seed(58694)
mylogit_ridge_acc <- train(
  Pobre ~ Pobre ~ Arriendo + PensionJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 1,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_ridge_acc
##Con un alpha de uno (Ridge) el lambda óptimo es de 1.023293

##Cambiando la métrica por la cual se elige el lambda se encontró que 
set.seed(2452)
mylogit_lasso_roc <- train(
  Pobre ~ Arriendo + PensionJefe_2  + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "ROC",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_roc
##Con un alpha de cero (Lasso) el lambda óptimo a partir del ROC es de 0.009007891.
##Los modelos anteriores están utilizando un cutoff de 1/2, por lo que busco el cutoff que se encuentre ubicado más cerca al ideal de la predicción del modelo
##Alternate cutoffs- en la muestra de evaluación de post-procesamiento es donde busco los cortes alternativos

evalResults <- data.frame(Pobre = evaluation$Pobre)
evalResults$Roc <- predict(mylogit_lasso_roc,
                           newdata = evaluation,
                           type = "prob")[,1]

library(pROC)
rfROC <- roc(evalResults$Pobre, evalResults$Roc, levels = rev(levels(evalResults$Pobre)))
plot(rfROC)
## Area under the curve: 0.7611, quiero encontrar el corte que esté más cercano al corte superior izquierdo

rfThresh <- coords(rfROC, x = "best", best.method = "closest.topleft")
rfThresh

## threshold specificity sensitivity
## 0.7948547   0.6968504   0.6949371

#Se compara con el punto de corte 1/2 y con el threshold de 0.79

evalResults<-evalResults %>% mutate(hat_def_05=ifelse(evalResults$Roc>0.5,"No Pobre","Pobre"),
                                    hat_def_rfThresh=ifelse(evalResults$Roc>rfThresh$threshold,"Pobre","No Pobre"))
with(evalResults,table(Pobre,hat_def_05))
##       hat_def_05
##Pobre      No Pobre Pobre
##No_Pobre    12932   262
##Pobre        2836   466

with(evalResults,table(Pobre,hat_def_rfThresh))
##        hat_def_rfThresh
##Pobre      No Pobre Pobre
##No_Pobre     4025  9169
##Pobre        2301  1001

##Se observa que con el threshold mejora la predicción de hogares pobres. 
##El training es una estimación del modelo más optimista 

##Remuestreo

##Por el desbalanceo de pobres y no pobres, procedo a realizar up-sampling y down-sampling para que estén balanceadas 

set.seed(1103)
upSampledTrain <- upSample(x = training,
                           y = training$Pobre,
                           ## keep the class variable name the same:
                           yname = "Pobre")
dim(training)
dim(upSampledTrain)
table(upSampledTrain$Pobre)

##Obtengo  92356  observaciones pobres y 92356 no pobres, la muestra está balanceada.

##Up-sampling

set.seed(1410)
mylogit_lasso_upsample <- train(
  Pobre ~ Arriendo + PensionJefe_2+ TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = upSampledTrain,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_upsample

##Nos brinda un lambda de 0.01305657

##Down sampling-se corre con diferentes semillas para obtener datos más robustos

set.seed(1103)
downSampledTrain <- downSample(x = training,
                               y = training$Pobre,
                               ## keep the class variable name the same:
                               yname = "Pobre")
dim(training)
dim(downSampledTrain)
table(downSampledTrain$Pobre)

set.seed(1104)
downSampledTrain <- downSample(x = training,
                               y = training$Pobre,
                               ## keep the class variable name the same:
                               yname = "Pobre")
set.seed(1410)
mylogit_lasso_downsample <- train(
  Pobre ~ Arriendo + PensionJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe,
  data = downSampledTrain,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)
mylogit_lasso_downsample

##Nos brinda un lambda de 0.01305657

##Ahora evalúo todo lo realizado con anterioridad sobre la base de testeo
##Se realizan las comparaciones
testResults <- data.frame(Pobre = testing$Pobre)
testResults$logit<- predict(mylogit_caret,
                            newdata = testing,
                            type = "prob")[,1]
testResults$lasso<- predict(mylogit_lasso_roc,
                            newdata = testing,
                            type = "prob")[,1]
testResults$lasso_thresh<- predict(mylogit_lasso_roc,
                                   newdata = testing,
                                   type = "prob")[,1]
testResults$lasso_upsample<- predict(mylogit_lasso_upsample,
                                     newdata = testing,
                                     type = "prob")[,1]
testResults$mylogit_lasso_downsample<- predict(mylogit_lasso_downsample,
                                               newdata = testing,
                                               type = "prob")[,1]

##Evaluación en el test
testResults<-testResults %>%
  mutate(logit=ifelse(logit>0.5,"No Pobre","Pobre"),
         lasso=ifelse(lasso>0.5,"No Pobre","Pobre"),
         lasso_thresh=ifelse(lasso_thresh>rfThresh$threshold,"No Pobre","Pobre"),
         lasso_upsample=ifelse(lasso_upsample>0.5,"No Pobre","Pobre"),
         mylogit_lasso_downsample=ifelse(mylogit_lasso_downsample>0.5,"No Pobre","Pobre"),
  )
with(testResults,table(Pobre,logit))

##        logit
## Pobre      No Pobre Pobre
## No_Pobre    25986   400
## Pobre        5511  1093

#Sensitivity 72.5 (1)- 73,2% (2)

with(testResults,table(Pobre,lasso))

##          lasso
## Pobre      No Pobre Pobre
## No_Pobre    25556   830
## Pobre        5031  1573

##Sensitivity 64,3% (1) -  65,4% (2)
with(testResults,table(Pobre,lasso_thresh))

##   lasso_thresh
##          lasso_thresh
##Pobre      No Pobre Pobre
##No_Pobre    18859  7527
##Pobre        1667  4937

##Sensitivity 41.7% (1)- 39,6% (2)

with(testResults,table(Pobre,lasso_upsample))

##          lasso_upsample
## Pobre      No Pobre Pobre
## No_Pobre    18767  7619
## Pobre        1651  4953

#sensit 40.5% (1) - 39,4 (2)

with(testResults,table(Pobre,mylogit_lasso_downsample))

##         mylogit_lasso_downsample
## Pobre      No Pobre Pobre
## No_Pobre    18739  7647
## Pobre        1633  4971

# sensit 40.4% (1) - 40,35% (2)

#A simple vista se observa que existe una mayor sensibilidad e identificación de hogares pobres como
##realmente pobres en el modelo logit esto es seguido del modelo lasso. 


#*******Segundo modelo de regresión*******

##Se prueban diferentes modelos para encontrar el más pertinente 

#Método de validación cruzada con cinco folds- se corta en cinco la base
ctrl_def <- trainControl(method = "cv",
                         number = 5,
                         summaryFunction = defaultSummary,
                         classProbs = TRUE,
                         verbose=FALSE,
                         savePredictions = T)

#Logit- fijo la semilla y aplico un logit con función binomial y las variables escaladas
set.seed(1234)
mylogit_caret_def <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl_def,
  family = "binomial",
  preProcess = c("center", "scale")
)
mylogit_caret_def
##Al correr el logit con la base de training se obtiene un accuracy de 0.80 y Kappa de 0.11. Es decir, que un 80% de las observaciones totales
##se clasificaron de manera correcta. El Kappa indica que hay poca concordancia entre los rates utilizados en el modelo. 

##Se corre lo mismo pero sacar más métricas del modelo

ctrl_two <- trainControl(method = "cv",
                         number = 5,
                         summaryFunction = twoClassSummary,
                         classProbs = TRUE,
                         verbose=FALSE,
                         savePredictions = T)

set.seed(1234)
mylogit_caret_two <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl_two,
  family = "binomial",
  preProcess = c("center", "scale")
)

mylogit_caret_two


fiveStats <- function(...) c(twoClassSummary(...), defaultSummary(...))
ctrl<- trainControl(method = "cv",
                    number = 5,
                    summaryFunction = fiveStats,
                    classProbs = TRUE,
                    verbose=FALSE,
                    savePredictions = T)
#logit
set.seed(18414)
mylogit_caret <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glm", #for logit
  trControl = ctrl,
  family = "binomial",
  preProcess = c("center", "scale")
)

mylogit_caret

## El área bajo la curva (ROC) es del 0.76, la Sensibilidad es de un 98% es decir que se detectan correctamente el 98% de los pobres que en verdad son pobres, y la especificidad es de 0.08, es decir que un 8% de los verdaderos no pobres son clasificados como tal.
##La métrica más relevante para este caso es la de sensibilidad debido a que quiero predecir los hogares debajo de la línea de pobreza.

##Para verificar la pertinencia de incluir las variables especificadas con anterioridad en el modelo se utiliza lasso con una grilla de 200
##A partir de esto se observa las diferentes penalizaciones y escogemos el lambda que maximiza la sensibilidad del modelo. Asimismo, se prueba Ridge y elastic net para elegir cuál funciona mejor.
#Lasso
lambda_grid <- 10^seq(-4, 0.01, length = 200) #en la practica se suele usar una grilla de 200 o 300
lambda_grid

set.seed(58694)
mylogit_lasso_acc <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_acc
##Con un alpha de cero (lasso) el lambda óptimo es de 1.023293



set.seed(58694)
mylogit_ridge_acc <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 1,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_ridge_acc
##Con un alpha de uno (Ridge) el lambda óptimo es de 1.023293

##Cambiando la métrica por la cual se elige el lambda se encontró que 
set.seed(2452)
mylogit_lasso_roc <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = training,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "ROC",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_roc
##Con un alpha de cero (Lasso) el lambda óptimo a partir del ROC es de 0.009007891.
##Los modelos anteriores están utilizando un cutoff de 1/2, por lo que busco el cutoff que se encuentre ubicado más cerca al ideal de la predicción del modelo
##Alternate cutoffs- en la muestra de evaluación de post-procesamiento es donde busco los cortes alternativos

evalResults <- data.frame(Pobre = evaluation$Pobre)
evalResults$Roc <- predict(mylogit_lasso_roc,
                           newdata = evaluation,
                           type = "prob")[,1]

library(pROC)
rfROC <- roc(evalResults$Pobre, evalResults$Roc, levels = rev(levels(evalResults$Pobre)))
plot(rfROC)
## Area under the curve: 0.7611, quiero encontrar el corte que esté más cercano al corte superior izquierdo

rfThresh <- coords(rfROC, x = "best", best.method = "closest.topleft")
rfThresh

## threshold specificity sensitivity
## 0.7948547   0.6968504   0.6949371

#Se compara con el punto de corte 1/2 y con el threshold de 0.79

evalResults<-evalResults %>% mutate(hat_def_05=ifelse(evalResults$Roc>0.5,"No Pobre","Pobre"),
                                    hat_def_rfThresh=ifelse(evalResults$Roc>rfThresh$threshold,"Pobre","No Pobre"))
with(evalResults,table(Pobre,hat_def_05))
##       hat_def_05
##Pobre      No Pobre Pobre
##No_Pobre    12932   262
##Pobre        2836   466

with(evalResults,table(Pobre,hat_def_rfThresh))
##        hat_def_rfThresh
##Pobre      No Pobre Pobre
##No_Pobre     4025  9169
##Pobre        2301  1001

##Se observa que con el threshold mejora la predicción de hogares pobres. 
##El training es una estimación del modelo más optimista 

##Remuestreo

##Por el desbalanceo de pobres y no pobres, procedo a realizar up-sampling y down-sampling para que estén balanceadas 

set.seed(1103)
upSampledTrain <- upSample(x = training,
                           y = training$Pobre,
                           ## keep the class variable name the same:
                           yname = "Pobre")
dim(training)
dim(upSampledTrain)
table(upSampledTrain$Pobre)

##Obtengo  92356  observaciones pobres y 92356 no pobres, la muestra está balanceada.

##Up-sampling

set.seed(1410)
mylogit_lasso_upsample <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = upSampledTrain,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)

mylogit_lasso_upsample

##Nos brinda un lambda de 0.01305657

##Down sampling-se corre con diferentes semillas para obtener datos más robustos

set.seed(1103)
downSampledTrain <- downSample(x = training,
                               y = training$Pobre,
                               ## keep the class variable name the same:
                               yname = "Pobre")
dim(training)
dim(downSampledTrain)
table(downSampledTrain$Pobre)

set.seed(1104)
downSampledTrain <- downSample(x = training,
                               y = training$Pobre,
                               ## keep the class variable name the same:
                               yname = "Pobre")
set.seed(1410)
mylogit_lasso_downsample <- train(
  Pobre ~ Arriendo + PensionJefe_2 + ArriendosPenJefe_2 + TipoTrabajoJefe_1  + Npersug + EducacionJefe_6 + P5090 + P5000 + EdadJefe + OcupadoJefe + HorasTrabJefe,
  data = downSampledTrain,
  method = "glmnet",
  trControl = ctrl,
  family = "binomial",
  metric = "Sens",
  tuneGrid = expand.grid(alpha = 0,lambda=lambda_grid),
  preProcess = c("center", "scale")
)
mylogit_lasso_downsample

##Nos brinda un lambda de 0.01305657

##Ahora evalúo todo lo realizado con anterioridad sobre la base de testeo
##Se realizan las comparaciones
testResults <- data.frame(Pobre = testing$Pobre)
testResults$logit<- predict(mylogit_caret,
                            newdata = testing,
                            type = "prob")[,1]
testResults$lasso<- predict(mylogit_lasso_roc,
                            newdata = testing,
                            type = "prob")[,1]
testResults$lasso_thresh<- predict(mylogit_lasso_roc,
                                   newdata = testing,
                                   type = "prob")[,1]
testResults$lasso_upsample<- predict(mylogit_lasso_upsample,
                                     newdata = testing,
                                     type = "prob")[,1]
testResults$mylogit_lasso_downsample<- predict(mylogit_lasso_downsample,
                                               newdata = testing,
                                               type = "prob")[,1]

##Evaluación en el test
testResults<-testResults %>%
  mutate(logit=ifelse(logit>0.5,"No Pobre","Pobre"),
         lasso=ifelse(lasso>0.5,"No Pobre","Pobre"),
         lasso_thresh=ifelse(lasso_thresh>rfThresh$threshold,"No Pobre","Pobre"),
         lasso_upsample=ifelse(lasso_upsample>0.5,"No Pobre","Pobre"),
         mylogit_lasso_downsample=ifelse(mylogit_lasso_downsample>0.5,"No Pobre","Pobre"),
  )
with(testResults,table(Pobre,logit))

#Sensitivity 72.5 (1)- 73,2% (2)

with(testResults,table(Pobre,lasso))

##Sensitivity 64,3% (1) -  65,4% (2)
with(testResults,table(Pobre,lasso_thresh))

##Sensitivity 41.7% (1)- 39,6% (2)

with(testResults,table(Pobre,lasso_upsample))

#sensit 40.5% (1) - 39,4 (2)

with(testResults,table(Pobre,mylogit_lasso_downsample))

# sensit 40.4% (1) - 40,35% (2)

#A simple vista se observa que existe una mayor sensibilidad e identificación de hogares pobres como
##realmente pobres en el modelo logit esto es seguido del modelo lasso. 


#Seleccionar el set de testeo en variables independientes y dependientes
XTest <- testDF
XTest$mylogit_caret<- predict(mylogit_caret,
                             newdata = testDF)

levels(XTest$mylogit_caret) <- c(0, 1)
table(XTest$mylogit_caret)
phat <- predict(mylogit_caret,
                             newdata = testDF)


testFinal<- data.frame(id = XTest$id, Pobre_classification = XTest$mylogit_caret)
write.csv(testFinal,"predictions_Lopez_Jaime_Nieto_c9_rx.csv", row.names = FALSE)

                             
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
#%    Income Regression Models 		          %
#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

#--------Modelo XGboost---------------------
#Se crea la base a utilizar
YTestReg <- hogares_test$Ingtotug
hogares_trainReg <- hogares_train %>% dplyr::select(-Ingpcug, -Pobre)
YTrainReg <- hogares_trainReg$Ingtotug
XTrainReg <- hogares_trainReg %>% dplyr::select(-Ingtotug)


set.seed(1948)
trControl1 <- trainControl(method='repeatedcv', 
                           number=5, 
                           repeats=1,
                           allowParallel = TRUE)


  grid_default <- expand.grid(nrounds = c(250,500),
                            max_depth = c(4,5,6),
                            eta = c(0.05),
                            gamma = c(0.01),
                            min_child_weight = c(10, 25, 50),
                            colsample_bytree = c(0.7),
                            subsample = c(0.6))

ModeloXGBoost <- train(
  Ingtotug ~ .,
  data = hogares_trainReg,
  method = "xgbTree",
  trControl = trControl1,
  tuneGrid = grid_default)


plot(ModeloXGBoost)
ModeloXGBoost
varImp(ModeloXGBoost,scale=TRUE)

YhatXG <-predict(ModeloXGBoost, XTest)
MSEXG <- sum((YTestReg-YhatXG)^2)/length(YTestReg)
RMSEXG <- sqrt(MSEXG)

MSEXGValor = 3495298557010.06
RMSEGValor = 1869571.75

XTestXG <- cbind(XTest, YhatXG)
XTestXG$PobrePredict <- ifelse(XTestXG$YhatXG > XTestXG$Npersug*XTestXG$Lp, 0, 1)
confusionMatrix(table(YTest, XTestXG$PobrePredict))


#---------------Lasso y Ridge-----------------------------------------------------

#Seleccionamos la base y la modificamos. La variable dependiente sera Ingtotug
#Se eliminan las variables que miden lo mismo 

hogares_train_ing<- dplyr::select(hogares_train,-Ingpcug, -Ingtotugarr, -Pobre)
hogares_test_ing <- dplyr::select(hogares_test, -id, -Dominio, -Depto, -OfJefe, -Ingpcug, -Ingtotugarr, -Pobre)

#Se crean las variables de entrenamiento 
YTrain_ing <- hogares_train_ing$Ingtotug
XTrain_ing <- dplyr::select(hogares_train_ing,-Ingtotug)

#Se crean las variables de test 
YTest_ing<-hogares_test_ing$Ingtotug
XTest_ing<-dplyr::select(hogares_test_ing,-Ingtotug)

#Estimacion modelo OLS 
modelo_OLS_ing<-lm(Ingtotug~ ., data = hogares_train_ing)
summary(modelo_OLS_ing) #Adjuted R-squared 0.3113
#Coeficientes del modelo OLS 
mt_coeficientes_ing <- modelo_OLS_ing$coefficients %>%
  enframe(name = "predictor", value = "coeficiente")

mt_coeficientes_ing %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo OLS Ingreso") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 5, angle = 45))
#Predicciones y MSE 
#Base de entrenamiento 
pred_OLS_train_ing<- predict(modelo_OLS_ing, newdata = hogares_train_ing)
OLS_training_mse_ing <- mean((pred_OLS_train_ing - YTrain_ing)^2)
paste("Error (mse) de entrenamiento:",OLS_training_mse_ing)
#Base de prueba 
pred_OLS_test_ing <- predict(modelo_OLS_ing, newdata = hogares_test_ing)
OLS_test_mse_ing<-mean((pred_OLS_test_ing - YTest_ing)^2)
paste("Error (mse) de test:", OLS_test_mse_ing)

#Regularizacion - Ridge 
require(glmnet)

#Se crean las matrices de entrenamiento y test 
x_train_ridge_ing <- model.matrix(Ingtotug~., data =hogares_train_ing)[, -1]
y_train_ridge_ing <- hogares_train_ing$Ingtotug

x_test_ridge_ing <- model.matrix(Ingtotug~., data = hogares_test_ing)[, -1]
y_test_ridge_ing <- hogares_test_ing$Ingtotug
#Creacion de modelo
#Para Ridge el alpha debe ser igual a 0 
modelo_ridge_ing <- glmnet(
  x           = x_test_ridge_ing,
  y           = y_test_ridge_ing,
  alpha       = 0,
  nlambda     = 100,
  standardize = TRUE
)

#Cambio de coeficientes en funcion de lambda 
regularizacion_ridge_ing <- modelo_ridge_ing$beta %>% 
  as.matrix() %>%
  t() %>% 
  as_tibble() %>%
  mutate(lambda = modelo_ridge_ing$lambda)

regularizacion_ridge_ing<- regularizacion_ridge_ing %>%
  pivot_longer(
    cols = !lambda, 
    names_to = "predictor",
    values_to = "coeficientes"
  )

regularizacion_ridge_ing %>%
  ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
  geom_line() +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  labs(title = "Coeficientes del modelo en función de la regularización Ingreso") +
  theme_bw() +
  theme(legend.position = "none")

#MSE en funcion de lambda
set.seed(0711)
cv_error_ridge_ing <- cv.glmnet(
  x      = x_train_ridge_ing,
  y      = y_train_ridge_ing,
  alpha  = 0,
  nfolds = 10,
  type.measure = "mse",
  standardize  = TRUE
)

plot(cv_error_ridge_ing)

#Encontramos el lambda que minimiza MSE 
paste("Mejor valor de lambda encontrado:", cv_error_ridge_ing$lambda.min)
#Mayor lambda que no se aleja más de 1 desviacion estandar del minimo 
paste("Mejor valor de lambda encontrado + 1 desviación estándar:", cv_error_ridge_ing$lambda.1se)

#Estimamos modelo usando mejor valor lambda mas una desviacion estandar 
modelo_lambda_ods_ing <- glmnet(
  x           = x_train_ridge_ing,
  y           = y_train_ridge_ing,
  alpha       = 0,
  lambda      = cv_error_ridge_ing$lambda.min,
  standardize = TRUE
)

#Analisis de coeficientes 
df_coeficientes_ridge <- coef(modelo_lambda_ods_ing) %>%
  as.matrix() %>%
  as_tibble(rownames = "predictor") %>%
  rename(coeficiente = s0)

df_coeficientes_ridge %>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo Ridge") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))
#Predicciones Ridge Train 
pred_ridge_train_ing <- predict(modelo_lambda_ods_ing, newx = x_train_ridge_ing)
#MSE train 
ridge_training_mse_ing <- mean((pred_ridge_train_ing - y_train_ridge_ing)^2)
paste("Error (mse) de entrenamiento:", ridge_training_mse_ing)
#Predicciones Ridge Test 
pred_ridge_test_ing <- predict(modelo_lambda_ods_ing, newx = x_test_ridge_ing)
#MSE test 
test_mse_ridge_ing <- mean((pred_ridge_test_ing - y_test_ridge_ing)^2)
paste("Error (mse) de test:", test_mse_ridge_ing)

#Regularizacion - Lasso 
#Matrices de entrenamiento y test
x_train_lasso_ing <- model.matrix(Ingtotug~., data = hogares_train_ing)[, -1]
y_train_lasso_ing <- hogares_train_ing$Ingtotug

x_test_lasso_ing <- model.matrix(Ingtotug~., data = hogares_test_ing)[, -1]
y_test_lasso_ing <- hogares_test_ing$Ingtotug

#Creacion del modelo 
modelo_ing_lasso <- glmnet(
  x           = x_train_lasso_ing,
  y           = y_train_lasso_ing,
  alpha       = 1,
  nlambda     = 100,
  standardize = TRUE
)

#Coeficientes en funcion de lambda 
regularizacion_lasso_ing <- modelo_ing_lasso$beta %>% 
  as.matrix() %>%
  t() %>% 
  as_tibble() %>%
  mutate(lambda = modelo_ing_lasso$lambda)

regularizacion_lasso_ing <- regularizacion_lasso_ing %>%
  pivot_longer(
    cols = !lambda, 
    names_to = "predictor",
    values_to = "coeficientes"
  )
regularizacion_lasso_ing %>%
  ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
  geom_line() +
  scale_x_log10(
    breaks = trans_breaks("log10", function(x) 10^x),
    labels = trans_format("log10", math_format(10^.x))
  ) +
  labs(title = "Coeficientes del modelo en función de la regularización Ingreso") +
  theme_bw() +
  theme(legend.position = "none")
#MSE en funcion de lambda 
set.seed(0711)
cv_error_lasso_ing <- cv.glmnet(
  x      = x_train_lasso_ing,
  y      = y_train_lasso_ing,
  alpha  = 1,
  nfolds = 10,
  type.measure = "mse",
  standardize  = TRUE
)

plot(cv_error_lasso_ing)

#Mejor lambda determinado 
paste("Mejor valor de lambda encontrado:", cv_error_lasso_ing$lambda.min)

#Mejor lambda a una desviacion estandar 
paste("Mejor valor de lambda encontrado + 1 desviación estándar:", cv_error_lasso_ing$lambda.1se)

#Estimacion de modelo con lambda optimo 
modelo_op_lasso_ing <- glmnet(
  x           = x_train_lasso_ing,
  y           = y_train_lasso_ing,
  alpha       = 1,
  lambda      = cv_error_lasso_ing$lambda.min,
  standardize = TRUE
)

#Coeficientes 
df_coef_lasso_ing<- coef(modelo_op_lasso_ing) %>%
  as.matrix() %>%
  as_tibble(rownames = "predictor") %>%
  rename(coeficiente = s0)

df_coef_lasso_ing%>%
  filter(predictor != "(Intercept)") %>%
  ggplot(aes(x = predictor, y = coeficiente)) +
  geom_col() +
  labs(title = "Coeficientes del modelo Lasso") +
  theme_bw() +
  theme(axis.text.x = element_text(size = 6, angle = 45))

df_coef_lasso_ing %>%
  filter(
    predictor != "(Intercept)",
    coeficiente != 0
  ) 

#Predicciones Ridge Train 
pred_lasso_train_ing <- predict(modelo_op_lasso_ing
                                , newx = x_train_lasso_ing)
#MSE train 
lasso_training_mse_ing <- mean((pred_lasso_train_ing - y_train_lasso_ing)^2)
paste("Error (mse) de entrenamiento:", lasso_training_mse_ing)
#Predicciones Ridge Test 
pred_lasso_test_ing <- predict(modelo_op_lasso_ing, newx = x_test_lasso_ing)
#MSE test 
lasso_test_mse_ing <- mean((pred_lasso_test_ing - y_test_lasso_ing)^2)
paste("Error (mse) de test:", lasso_test_mse_ing)

#-----------------Resultados preliminares regresion----------------------------------
#Se puede ver que en los modelos XGboost y Lasso hay un mayor peso de algunas variables.
#En el caso de XGBoost las variables más importantes son Arriendo (que se crea apartir de P5130 y P5140,
#Si no cotiza a pensión, el número de cuartos, la edad del jefe del hogar, si recibe ingresos por arriendo o pension,
#La educación del jefe del hogar, el tipo de vivienda que viven, y el tiempo que lleva en la empresa)
#Con esto en mente se crearán nuevos modelos para ser más precisos.
#Por otro lado, se utilizará la variable ingtotugarr porque vimos que tiene una relación muy grande con la variable
# arriendo y además es la que se usa para medir la linea de pobreza de los hogares

MSEValores <- c(OLS_test_mse_ing, test_mse_ridge_ing, lasso_test_mse_ing, MSEXG)
RMSEValores <- sapply(MSEValores, sqrt)
ModeloNombre <- c("Modelo OLS", "Modelo Ridge", "Modelo Lasso", "Modelo XGBoost")

ResultadosInicialesRegresio <- data.frame(ModeloNombre, MSEValores, RMSEValores)

#--------------Elegir la distribución del ingreso----------------------------
# Construimos el vector de los ingresos y eliminamos los NAs 
x <- hogares_train$Ingtotugarr[!is.na(hogares_train$Ingtotugarr)]
x <- hogares_train$Ingtotugarr[hogares_train$Ingtotugarr!=0]
sk_x <- skewness(x)
print(paste("El valor de skewness para los ingresos totales es", round(sk_x, 2)))
##El Skewness es de 5.37

x <- log(hogares_train$Ingtotugarr[!is.na(hogares_train$Ingtotugarr)])
x <- hogares_train$Ingtotugarr[hogares_train$Ingtotugarr!=0]
sk_x <- skewness(x)
print(paste("El valor de skewness para los ingresos totales es", round(sk_x, 2)))

##Al realizar la distribución logarítmica el skewness es el mismo

# Vamos a aplicar diferentes transformaciones y a visualizar como cambia el skewness
# Encontrar lambda óptimo
lambda <- boxcox(x, objective.name = "Log-Likelihood", 
                 optimize = TRUE)$lambda
box_cox_x <- boxcoxTransform(x, lambda)

ing_totimputado <- data.frame("Ingresos totales" = x,
                              "Logaritmo" = log(x),
                              "Raiz cuadrada" = sqrt(x),
                              "Inversa" = 1/x,
                              "Box-Cox" = box_cox_x)

# Observemos la distribución original
p1 <- ggplot(ing_totimputado) +
  geom_histogram(aes(x = Ingresos.totales, 
                     fill = "Ingresos totales"), 
                 alpha = 0.5, fill = "gray", bins = 30) +
  geom_text(aes(x = Inf, y = Inf, hjust = 1, 
                vjust = 1, 
                label = paste("Skewness", round(sk_x, 2)))) +
  theme_classic() +
  labs(x = "Ingresos totales", y = "Cantidad") +
  scale_x_continuous(labels = scales::dollar)

sk_x2 <- skewness(ing_totimputado$Logaritmo)
p2 <- ggplot(ing_totimputado) +
  geom_histogram(aes(x = Logaritmo, 
                     fill = "Logaritmo"), 
                 alpha = 0.5, fill = "blue", bins = 30) +
  geom_text(aes(x = Inf, y = Inf, hjust = 1, 
                vjust = 1, 
                label = paste("Skewness", round(sk_x2, 2)))) +
  theme_classic() +
  labs(x = "Log(Ingresos totales)", y = "Cantidad") 

sk_x3 <- skewness(ing_totimputado$Raiz.cuadrada)
p3 <- ggplot(ing_totimputado) +
  geom_histogram(aes(x = Raiz.cuadrada, 
                     fill = "Raíz cuadrada"), 
                 alpha = 0.5, fill = "red", bins = 30) +
  geom_text(aes(x = Inf, y = Inf, hjust = 1, 
                vjust = 1, 
                label = paste("Skewness", round(sk_x3, 2)))) +
  theme_classic() +
  labs(x = "Raiz cuadrada de Ingresos totales", y = "Cantidad") 

sk_x4 <- skewness(ing_totimputado$Inversa)
p4 <- ggplot(ing_totimputado) +
  geom_histogram(aes(x = Inversa, 
                     fill = "Inversa"), 
                 alpha = 0.5, fill = "green", bins = 30) +
  geom_text(aes(x = Inf, y = Inf, hjust = 1, 
                vjust = 1, 
                label = paste("Skewness", round(sk_x4, 2)))) +
  theme_classic() +
  labs(x = "1/(Ingresos totales)", y = "Cantidad")

sk_x5 <- skewness(ing_totimputado$Box.Cox)
p5 <- ggplot(ing_totimputado) +
  geom_histogram(aes(x = Box.Cox, 
                     fill = "Box-Cox"), 
                 alpha = 0.5, fill = "purple", bins = 30) +
  geom_text(aes(x = Inf, y = Inf, hjust = 1, 
                vjust = 1, 
                label = paste("Skewness", round(sk_x5, 2)))) +
  theme_classic() +
  labs(x = "Transformacion Box-Cox de Ingresos totales", 
       y = "Cantidad")

ggarrange(p1, p2, p3, p4, p5, nrow = 3, ncol = 2)

##U otra opción es 

(p1 | p2 | p3) /
  (p4 | p5)

##Se concluye que la variable dependiente con un menor skewness es con la distribución Box-Cox, aunque la logarítmica
#También tiene un bajo skewness, y para transformación es mucho más fácil. Por tal motivo se usará el logaritmo
#Para predecir los ingresos

glimpse(hogares_train)

#----------Modelo 5 Elastic Net-------
el <- train(
  Ingtotugarr ~ Arriendo + PensionJefe_2 + P5000 + ArriendosPenJefe_2 + as.factor(P5090) , data = hogares_train, method = "glmnet",
  trControl = trainControl("cv", number = 10), preProcess = c("center", "scale"))

plot(el)
el

YhatEl <- predict(el, hogares_test)
MSEtest_el <- mean((YTest_ing - YhatEl)^2)
paste("Error (mse) de test:", MSEtest_el)
RMSE_el <- sqrt(MSEtest_el)

ModeloElStats <- c("Elastic Net", MSEtest_el, RMSE_el)

ResultadosInicialesRegresio <- rbind(ResultadosInicialesRegresio, ModeloElStats)


#-----------------Modelo 6------------------
ModeloPv <- lm(Ingtotugarr ~ Arriendo + PensionJefe_2 + JefeMujer + EdadJefe + as.factor(P5090) + HorasTrabJefe, 
               data = hogares_train)

summary(ModeloPv)

YModeloPv <- predict(ModeloPv, hogares_test)
MSEtestModeloPV <- mean((YTest_ing - YModeloPv)^2)
RMSE_Pv <- sqrt(MSEtestModeloPV)
ModeloPvStats <- c("Modelo Pv", MSEtestModeloPV, RMSE_Pv)

ResultadosInicialesRegresio <- rbind(ResultadosInicialesRegresio, ModeloPvStats)

#------Modelo Ridge 7-----------

set.seed(1948)

lambda = 10^seq(-2, 3, length = 10)
ridge_caret<- train(Ingtotugarr ~ JefeMujer + EdadJefe + EducacionJefe_2 + EducacionJefe_3 + EducacionJefe_4 + EducacionJefe_5 + EducacionJefe_6 + ActividadJefe_2 + ActividadJefe_3 + ActividadJefe_4 + ActividadJefe_5 + ActividadJefe_6,
                    data = hogares_train, 
                    method = "glmnet",
                    trControl = trainControl("cv", number = 10),
                    preProcess = c("center","scale"),
                    tuneGrid = expand.grid(alpha = 0,
                                           lambda = lambda))

plot(ridge_caret)
ridge_caret
summary(ridge_caret)

Yridge_caret <- predict(ridge_caret, hogares_test)
MSEtestridge_caret <- mean((YTest_ing - Yridge_caret)^2)
RMSE_rc <- sqrt(MSEtestridge_caret)
ridge_caretStats <- c("Modelo RidgeEducacionYActividad", MSEtestridge_caret, RMSE_rc)

ResultadosInicialesRegresio <- rbind(ResultadosInicialesRegresio, ridge_caretStats)
write.csv(ResultadosInicialesRegresio,"ResultadosDeModelos.csv", row.names = FALSE)


#---------Creacion de CVS---------------

#Después de correr varios modelos, se muestra que el modelo con menor error es el de XGBoost.
#Estos son los resultados con la evaluación del train
XTestXG <- cbind(XTest, YhatXG)
XTestXG$PobrePredict <- ifelse(XTestXG$YhatXG > XTestXG$Npersug*XTestXG$Lp, 0, 1)
confusionMatrix(table(YTest, XTestXG$PobrePredict))

#Ahora se hará el predict con la base de test final
testDF$SSJefe_3 <- 0

IngtotUgArrHat <- predict(ModeloXGBoost, testDF)
testDF <- cbind(testDF[-1,], IngtotUgArrHat)
testDF$PobrePredict <- ifelse(testDF$IngtotUgArrHat > testDF$Npersug*testDF$Lp, 0, 1)

testFinalReg <-data.frame(id = testDF$id, Pobre_classificationReg = testDF$PobrePredict)
write.csv(testFinalReg,"predictions_Lopez_Jaime_Nieto_RegresionXGBoost.csv", row.names = FALSE)

library(readr)
ModeloClasificacion <- read_delim("predictions_Lopez_Jaime_Nieto_c9_rx.csv", 
                                                  delim = ";", escape_double = FALSE, trim_ws = TRUE)
